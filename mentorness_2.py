# -*- coding: utf-8 -*-
"""Mentorness#2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oNt8ZFqfr7J6u0q7vN7z19390pScnxCr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/goldstock.csv')
df.head()

df['Date'] = pd.to_datetime(df['Date'])

# Set the 'Date' column as the index
df.set_index('Date', inplace=True)

# Display the summary of the dataset
print(df.info())

scaler = MinMaxScaler()

columns_to_scale = ['Close', 'Volume', 'Open', 'High', 'Low']

df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])

print(df.head())

plt.figure(figsize=(14, 7))
plt.plot(df['Close'], label='Close Price', color='blue')
plt.plot(df['Open'], label='Open Price', color='green')
plt.plot(df['High'], label='High Price', color='red')
plt.plot(df['Low'], label='Low Price', color='purple')
plt.title('Gold Prices Over Time')
plt.xlabel('Date')
plt.ylabel('Scaled Price')
plt.legend()
plt.show()

# EDA: Summary Statistics
summary_stats = df.describe()
print("Summary Statistics:")
print(summary_stats)

# EDA: Visualizing Distributions
plt.figure(figsize=(14, 10))

plt.subplot(2, 2, 1)
plt.hist(df['Close'], bins=50, color='blue', alpha=0.7)
plt.title('Close Price Distribution')

plt.subplot(2, 2, 2)
plt.hist(df['Open'], bins=50, color='green', alpha=0.7)
plt.title('Open Price Distribution')

plt.subplot(2, 2, 3)
plt.hist(df['High'], bins=50, color='red', alpha=0.7)
plt.title('High Price Distribution')

plt.subplot(2, 2, 4)
plt.hist(df['Low'], bins=50, color='purple', alpha=0.7)
plt.title('Low Price Distribution')

plt.tight_layout()
plt.show()

# Visualizing the trading volume distribution
plt.figure(figsize=(7, 5))
plt.hist(df['Volume'], bins=50, color='orange', alpha=0.7)
plt.title('Volume Distribution')
plt.xlabel('Scaled Volume')
plt.ylabel('Frequency')
plt.show()

# Decompose the time series
result = seasonal_decompose(df['Close'], model='additive', period=365)
result.plot()
plt.show()

# Plot ACF and PACF
plt.figure(figsize=(14, 7))

# Autocorrelation Function
plt.subplot(2, 1, 1)
plot_acf(df['Close'].dropna(), lags=50, ax=plt.gca())
plt.title('Autocorrelation Function (ACF)')

# Partial Autocorrelation Function
plt.subplot(2, 1, 2)
plot_pacf(df['Close'].dropna(), lags=50, ax=plt.gca())
plt.title('Partial Autocorrelation Function (PACF)')

plt.tight_layout()
plt.show()

# Create lagged features
def create_lagged_features(data, lags=5):
    df = pd.DataFrame(data)
    columns = [df.shift(i) for i in range(1, lags + 1)]
    columns.append(df)
    df = pd.concat(columns, axis=1)
    df.columns = [f'lag_{i}' for i in range(lags, 0, -1)] + ['target']
    df.dropna(inplace=True)
    return df

lags = 5
data_with_lags = create_lagged_features(df['Close'].values, lags)

# Split the data into features (X) and target (y)
X = data_with_lags.drop('target', axis=1).values
y = data_with_lags['target'].values

# Split the data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

print(f"Training set size: {len(X_train)}")
print(f"Testing set size: {len(X_test)}")

# Train the linear regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = lr_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# Plot the actual vs predicted values
plt.figure(figsize=(12, 6))
plt.plot(df.index[train_size + lags:], y_test, label='Actual Prices')
plt.plot(df.index[train_size + lags:], y_pred, label='Predicted Prices')
plt.legend(loc='best')
plt.title('Linear Regression Model Forecast')
plt.show()

from sklearn.ensemble import RandomForestRegressor
# Initialize the Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)
# Calculate performance metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')
# Plot the actual vs predicted values
plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual Prices')
plt.plot(y_pred, label='Predicted Prices')
plt.title('Random Forest Model')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

# Calculate short-term (50-day) and long-term (200-day) moving averages
df['SMA_50'] = df['Close'].rolling(window=50).mean()
df['SMA_200'] = df['Close'].rolling(window=200).mean()

# Initialize the 'Signal' column
df['Signal'] = 0

# Generate trading signals using iloc for integer-based indexing
df.iloc[50:, df.columns.get_loc('Signal')] = np.where(df.iloc[50:, df.columns.get_loc('SMA_50')] > df.iloc[50:, df.columns.get_loc('SMA_200')], 1, 0)

# Calculate the 'Position' column
df['Position'] = df['Signal'].diff()

# Plot the signals on the price chart
plt.figure(figsize=(12, 6))
plt.plot(df['Close'], label='Close Price')
plt.plot(df['SMA_50'], label='50-Day SMA')
plt.plot(df['SMA_200'], label='200-Day SMA')

# Plot buy signals
plt.plot(df[df['Position'] == 1].index,
         df['SMA_50'][df['Position'] == 1],
         '^', markersize=10, color='g', lw=0, label='Buy Signal')

# Plot sell signals
plt.plot(df[df['Position'] == -1].index,
         df['SMA_50'][df['Position'] == -1],
         'v', markersize=10, color='r', lw=0, label='Sell Signal')

plt.title('Gold Prices with Buy and Sell Signals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

# Calculate returns
df['Gold Returns'] = df['Close'].pct_change()
df['Strategy Returns'] = df['Gold Returns'] * df['Position'].shift(1)

# Calculate cumulative returns
df['Cumulative Gold Returns'] = (1 + df['Gold Returns']).cumprod() - 1
df['Cumulative Strategy Returns'] = (1 + df['Strategy Returns']).cumprod() - 1

# Plot cumulative returns
df[['Cumulative Gold Returns', 'Cumulative Strategy Returns']].plot(figsize=(10, 6))
plt.title('Cumulative Returns: Gold vs. Strategy')
plt.show()

# Performance metrics
sharpe_ratio = df['Strategy Returns'].mean() / df['Strategy Returns'].std() * np.sqrt(252)
max_drawdown = (df['Cumulative Strategy Returns'].cummax() - df['Cumulative Strategy Returns']).max()

print(f'Sharpe Ratio: {sharpe_ratio}')
print(f'Max Drawdown: {max_drawdown}')

import nltk
from textblob import TextBlob
nltk.download('punkt')

# Example event data (In practice, collect this from news websites or APIs)
events = [
    "Gold prices are expected to rise due to economic uncertainty.",
    "Investors are losing confidence in gold as an asset.",
    "Central banks are increasing their gold reserves.",
    "The gold market is experiencing high volatility."
]

# Analyze sentiment
for event in events:
    analysis = TextBlob(event)
    print(f'Event: {event}')
    print(f'Sentiment: {analysis.sentiment}\n')

